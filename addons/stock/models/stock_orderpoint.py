#-*-coding:utf-8-*-
#PartofFlectra.SeeLICENSEfileforfullcopyrightandlicensingdetails.

importlogging
fromcollectionsimportdefaultdict
fromdatetimeimportdatetime,time
fromdateutilimportrelativedelta
fromitertoolsimportgroupby
fromjsonimportdumps
frompsycopg2importOperationalError

fromflectraimportSUPERUSER_ID,_,api,fields,models,registry
fromflectra.addons.stock.models.stock_ruleimportProcurementException
fromflectra.exceptionsimportUserError,ValidationError
fromflectra.osvimportexpression
fromflectra.toolsimportadd,float_compare,frozendict,split_every,format_date

_logger=logging.getLogger(__name__)


classStockWarehouseOrderpoint(models.Model):
    """DefinesMinimumstockrules."""
    _name="stock.warehouse.orderpoint"
    _description="MinimumInventoryRule"
    _check_company_auto=True
    _order="location_id,company_id,id"

    @api.model
    defdefault_get(self,fields):
        res=super().default_get(fields)
        warehouse=None
        if'warehouse_id'notinresandres.get('company_id'):
            warehouse=self.env['stock.warehouse'].search([('company_id','=',res['company_id'])],limit=1)
        ifwarehouse:
            res['warehouse_id']=warehouse.id
            res['location_id']=warehouse.lot_stock_id.id
        returnres

    @api.model
    def_domain_product_id(self):
        domain="('type','=','product')"
        ifself.env.context.get('active_model')=='product.template':
            product_template_id=self.env.context.get('active_id',False)
            domain=f"('product_tmpl_id','=',{product_template_id})"
        elifself.env.context.get('default_product_id',False):
            product_id=self.env.context.get('default_product_id',False)
            domain=f"('id','=',{product_id})"
        returnf"[{domain},'|',('company_id','=',False),('company_id','=',company_id)]"

    name=fields.Char(
        'Name',copy=False,required=True,readonly=True,
        default=lambdaself:self.env['ir.sequence'].next_by_code('stock.orderpoint'))
    trigger=fields.Selection([
        ('auto','Auto'),('manual','Manual')],string='Trigger',default='auto',required=True)
    active=fields.Boolean(
        'Active',default=True,
        help="IftheactivefieldissettoFalse,itwillallowyoutohidetheorderpointwithoutremovingit.")
    snoozed_until=fields.Date('Snoozed',help="Hiddenuntilnextscheduler.")
    warehouse_id=fields.Many2one(
        'stock.warehouse','Warehouse',
        check_company=True,ondelete="cascade",required=True)
    location_id=fields.Many2one(
        'stock.location','Location',index=True,
        ondelete="cascade",required=True,check_company=True)
    product_tmpl_id=fields.Many2one('product.template',related='product_id.product_tmpl_id')
    product_id=fields.Many2one(
        'product.product','Product',index=True,
        domain=lambdaself:self._domain_product_id(),
        ondelete='cascade',required=True,check_company=True)
    product_category_id=fields.Many2one('product.category',name='ProductCategory',related='product_id.categ_id',store=True)
    product_uom=fields.Many2one(
        'uom.uom','UnitofMeasure',related='product_id.uom_id')
    product_uom_name=fields.Char(string='Productunitofmeasurelabel',related='product_uom.display_name',readonly=True)
    product_min_qty=fields.Float(
        'MinQuantity',digits='ProductUnitofMeasure',required=True,default=0.0,
        help="WhenthevirtualstockequalstoorgoesbelowtheMinQuantityspecifiedforthisfield,Flectragenerates"
             "aprocurementtobringtheforecastedquantitytotheMaxQuantity.")
    product_max_qty=fields.Float(
        'MaxQuantity',digits='ProductUnitofMeasure',required=True,default=0.0,
        help="WhenthevirtualstockgoesbelowtheMinQuantity,Flectragenerates"
             "aprocurementtobringtheforecastedquantitytotheQuantityspecifiedasMaxQuantity.")
    qty_multiple=fields.Float(
        'MultipleQuantity',digits='ProductUnitofMeasure',
        default=1,required=True,
        help="Theprocurementquantitywillberoundeduptothismultiple. Ifitis0,theexactquantitywillbeused.")
    group_id=fields.Many2one(
        'procurement.group','ProcurementGroup',copy=False,
        help="Movescreatedthroughthisorderpointwillbeputinthisprocurementgroup.Ifnoneisgiven,themovesgeneratedbystockruleswillbegroupedintoonebigpicking.")
    company_id=fields.Many2one(
        'res.company','Company',required=True,index=True,
        default=lambdaself:self.env.company)
    allowed_location_ids=fields.One2many(comodel_name='stock.location',compute='_compute_allowed_location_ids')

    rule_ids=fields.Many2many('stock.rule',string='Rulesused',compute='_compute_rules')
    json_lead_days_popover=fields.Char(compute='_compute_json_popover')
    lead_days_date=fields.Date(compute='_compute_lead_days')
    allowed_route_ids=fields.Many2many('stock.location.route',compute='_compute_allowed_route_ids')
    route_id=fields.Many2one(
        'stock.location.route',string='PreferredRoute',domain="[('id','in',allowed_route_ids)]")
    qty_on_hand=fields.Float('OnHand',readonly=True,compute='_compute_qty')
    qty_forecast=fields.Float('Forecast',readonly=True,compute='_compute_qty')
    qty_to_order=fields.Float('ToOrder',compute='_compute_qty_to_order',store=True,readonly=False)


    _sql_constraints=[
        ('qty_multiple_check','CHECK(qty_multiple>=0)','QtyMultiplemustbegreaterthanorequaltozero.'),
    ]

    @api.depends('warehouse_id')
    def_compute_allowed_location_ids(self):
        loc_domain=[('usage','in',('internal','view'))]
        #Wewanttokeeponlythelocations
        # -strictlybelongingtoourwarehouse
        # -notbelongingtoanywarehouses
        fororderpointinself:
            other_warehouses=self.env['stock.warehouse'].search([('id','!=',orderpoint.warehouse_id.id)])
            forview_location_idinother_warehouses.mapped('view_location_id'):
                loc_domain=expression.AND([loc_domain,['!',('id','child_of',view_location_id.id)]])
                loc_domain=expression.AND([loc_domain,['|',('company_id','=',False),('company_id','=',orderpoint.company_id.id)]])
            orderpoint.allowed_location_ids=self.env['stock.location'].search(loc_domain)

    @api.depends('warehouse_id','location_id')
    def_compute_allowed_route_ids(self):
        route_by_product=self.env['stock.location.route'].search([
            ('product_selectable','=',True),
        ])
        self.allowed_route_ids=route_by_product.ids

    @api.depends('rule_ids','product_id.seller_ids','product_id.seller_ids.delay')
    def_compute_json_popover(self):
        FloatConverter=self.env['ir.qweb.field.float']
        fororderpointinself:
            ifnotorderpoint.product_idornotorderpoint.location_id:
                orderpoint.json_lead_days_popover=False
                continue
            dummy,lead_days_description=orderpoint.rule_ids._get_lead_days(orderpoint.product_id)
            orderpoint.json_lead_days_popover=dumps({
                'title':_('Replenishment'),
                'icon':'fa-area-chart',
                'popoverTemplate':'stock.leadDaysPopOver',
                'lead_days_date':format_date(self.env,orderpoint.lead_days_date),
                'lead_days_description':lead_days_description,
                'today':format_date(self.env,fields.Date.today()),
                'trigger':orderpoint.trigger,
                'qty_forecast':FloatConverter.value_to_html(orderpoint.qty_forecast,{'decimal_precision':'ProductUnitofMeasure'}),
                'qty_to_order':FloatConverter.value_to_html(orderpoint.qty_to_order,{'decimal_precision':'ProductUnitofMeasure'}),
                'product_min_qty':FloatConverter.value_to_html(orderpoint.product_min_qty,{'decimal_precision':'ProductUnitofMeasure'}),
                'product_max_qty':FloatConverter.value_to_html(orderpoint.product_max_qty,{'decimal_precision':'ProductUnitofMeasure'}),
                'product_uom_name':orderpoint.product_uom_name,
                'virtual':orderpoint.trigger=='manual'andorderpoint.create_uid.id==SUPERUSER_ID,
            })

    @api.depends('rule_ids','product_id.seller_ids','product_id.seller_ids.delay')
    def_compute_lead_days(self):
        fororderpointinself.with_context(bypass_delay_description=True):
            ifnotorderpoint.product_idornotorderpoint.location_id:
                orderpoint.lead_days_date=False
                continue
            lead_days,dummy=orderpoint.rule_ids._get_lead_days(orderpoint.product_id)
            lead_days_date=fields.Date.today()+relativedelta.relativedelta(days=lead_days)
            orderpoint.lead_days_date=lead_days_date

    @api.depends('route_id','product_id','location_id','company_id','warehouse_id','product_id.route_ids')
    def_compute_rules(self):
        fororderpointinself:
            ifnotorderpoint.product_idornotorderpoint.location_id:
                orderpoint.rule_ids=False
                continue
            orderpoint.rule_ids=orderpoint.product_id._get_rules_from_location(orderpoint.location_id,route_ids=orderpoint.route_id)

    @api.constrains('product_id')
    def_check_product_uom(self):
        '''CheckiftheUoMhasthesamecategoryastheproductstandardUoM'''
        ifany(orderpoint.product_id.uom_id.category_id!=orderpoint.product_uom.category_idfororderpointinself):
            raiseValidationError(_('Youhavetoselectaproductunitofmeasurethatisinthesamecategoryasthedefaultunitofmeasureoftheproduct'))

    @api.onchange('location_id')
    def_onchange_location_id(self):
        warehouse=self.location_id.get_warehouse().id
        ifwarehouse:
            self.warehouse_id=warehouse

    @api.onchange('warehouse_id')
    def_onchange_warehouse_id(self):
        """Findslocationidforchangedwarehouse."""
        ifself.warehouse_id:
            self.location_id=self.warehouse_id.lot_stock_id.id
        else:
            self.location_id=False

    @api.onchange('product_id')
    def_onchange_product_id(self):
        ifself.product_id:
            self.product_uom=self.product_id.uom_id.id

    @api.onchange('company_id')
    def_onchange_company_id(self):
        ifself.company_id:
            self.warehouse_id=self.env['stock.warehouse'].search([
                ('company_id','=',self.company_id.id)
            ],limit=1)

    defwrite(self,vals):
        if'company_id'invals:
            fororderpointinself:
                iforderpoint.company_id.id!=vals['company_id']:
                    raiseUserError(_("Changingthecompanyofthisrecordisforbiddenatthispoint,youshouldratherarchiveitandcreateanewone."))
        returnsuper().write(vals)

    @api.model
    defaction_open_orderpoints(self):
        returnself._get_orderpoint_action()

    defaction_replenish(self):
        now=datetime.now()
        self._procure_orderpoint_confirm(company_id=self.env.company)
        notification=False
        iflen(self)==1:
            notification=self.with_context(written_after=now)._get_replenishment_order_notification()
        #Forcedtocallcomputequantitybecausewedon'thavealink.
        self._compute_qty()
        self.filtered(lambdao:o.create_uid.id==SUPERUSER_IDando.qty_to_order<=0.0ando.trigger=='manual').unlink()
        returnnotification

    defaction_replenish_auto(self):
        self.trigger='auto'
        returnself.action_replenish()

    @api.depends('product_id','location_id','product_id.stock_move_ids','product_id.stock_move_ids.state',
                 'product_id.stock_move_ids.date','product_id.stock_move_ids.product_uom_qty')
    def_compute_qty(self):
        orderpoints_contexts=defaultdict(lambda:self.env['stock.warehouse.orderpoint'])
        fororderpointinself:
            ifnotorderpoint.product_idornotorderpoint.location_id:
                orderpoint.qty_on_hand=False
                orderpoint.qty_forecast=False
                continue
            orderpoint_context=orderpoint._get_product_context()
            product_context=frozendict({**orderpoint_context})
            orderpoints_contexts[product_context]|=orderpoint
        fororderpoint_context,orderpoints_by_contextinorderpoints_contexts.items():
            products_qty=orderpoints_by_context.product_id.with_context(orderpoint_context)._product_available()
            products_qty_in_progress=orderpoints_by_context._quantity_in_progress()
            fororderpointinorderpoints_by_context:
                orderpoint.qty_on_hand=products_qty[orderpoint.product_id.id]['qty_available']
                orderpoint.qty_forecast=products_qty[orderpoint.product_id.id]['virtual_available']+products_qty_in_progress[orderpoint.id]

    @api.depends('qty_multiple','qty_forecast','product_min_qty','product_max_qty')
    def_compute_qty_to_order(self):
        fororderpointinself:
            ifnotorderpoint.product_idornotorderpoint.location_id:
                orderpoint.qty_to_order=False
                continue
            qty_to_order=0.0
            rounding=orderpoint.product_uom.rounding
            iffloat_compare(orderpoint.qty_forecast,orderpoint.product_min_qty,precision_rounding=rounding)<0:
                qty_to_order=max(orderpoint.product_min_qty,orderpoint.product_max_qty)-orderpoint.qty_forecast

                remainder=orderpoint.qty_multiple>0andqty_to_order%orderpoint.qty_multipleor0.0
                iffloat_compare(remainder,0.0,precision_rounding=rounding)>0:
                    qty_to_order+=orderpoint.qty_multiple-remainder
            orderpoint.qty_to_order=qty_to_order

    def_set_default_route_id(self):
        """Writethe`route_id`fieldon`self`.Thismethodisintendendtobecalledonthe
        orderpointsgeneratedwhenopenningthereplenishreport.
        """
        self=self.filtered(lambdao:noto.route_id)
        rules_groups=self.env['stock.rule'].read_group([
            ('route_id.product_selectable','!=',False),
            ('location_id','in',self.location_id.ids),
            ('action','in',['pull_push','pull'])
        ],['location_id','route_id'],['location_id','route_id'],lazy=False)
        forginrules_groups:
            ifnotg.get('route_id'):
                continue
            orderpoints=self.filtered(lambdao:o.location_id.id==g['location_id'][0])
            orderpoints.route_id=g['route_id']

    def_get_product_context(self):
        """Usedtocall`virtual_available`whenrunninganorderpoint."""
        self.ensure_one()
        return{
            'location':self.location_id.id,
            'to_date':datetime.combine(self.lead_days_date,time.max)
        }

    def_get_orderpoint_action(self):
        """Createmanualorderpointsformissingproductineachwarehouses.Italsoremoves
        orderpointsthathavebeenreplenish.Inordertodoit:
        -Itusesthereport.stock.quantitytofindmissingquantityperproduct/warehouse
        -Itchecksiforderpointalreadyexisttorefillthislocation.
        -Itchecksifitexistsothersources(e.gRFQ)tharefillthewarehouse.
        -Itcreatestheorderpointsformissingquantitythatwerenotrefillbyanupperoption.

        returnreplenishreportir.actions.act_window
        """
        action=self.env["ir.actions.actions"]._for_xml_id("stock.action_orderpoint_replenish")
        action['context']=self.env.context
        #Searchalsowitharchivedonestoavoidtotriggerproduct_location_checkSQLconstraintslater
        #Itmeansthatwhentherewillbeaarchivedorderpointonalocation+product,thereplenishment
        #reportwon'ttakeinaccountthislocation+productanditwon'tcreateanymanualorderpoint
        #Inmaster:theactivefieldshouldberemove
        orderpoints=self.env['stock.warehouse.orderpoint'].with_context(active_test=False).search([])
        #Removepreviousautomaticallycreatedorderpointthathasbeenrefilled.
        to_remove=orderpoints.filtered(lambdao:o.create_uid.id==SUPERUSER_IDando.qty_to_order<=0.0ando.trigger=='manual')
        to_remove.unlink()
        orderpoints=orderpoints-to_remove
        to_refill=defaultdict(float)
        all_product_ids=[]
        all_warehouse_ids=[]
        #Take3monthssinceit'sthemaxfortheforecastreport
        to_date=add(fields.date.today(),months=3)
        qty_by_product_warehouse=self.env['report.stock.quantity'].read_group(
            [('date','=',to_date),('state','=','forecast')],
            ['product_id','product_qty','warehouse_id'],
            ['product_id','warehouse_id'],lazy=False)
        forgroupinqty_by_product_warehouse:
            warehouse_id=group.get('warehouse_id')andgroup['warehouse_id'][0]
            ifgroup['product_qty']>=0.0ornotwarehouse_id:
                continue
            all_product_ids.append(group['product_id'][0])
            all_warehouse_ids.append(warehouse_id)
            to_refill[(group['product_id'][0],warehouse_id)]=group['product_qty']
        ifnotto_refill:
            returnaction

        #Recomputetheforecastedquantityformissingproducttodaybutatthistime
        #withtheirrealleaddays.
        key_to_remove=[]

        #groupproductbylead_daysandwarehouseinordertoreadvirtual_available
        #inbatch
        pwh_per_day=defaultdict(list)
        for(product,warehouse),quantityinto_refill.items():
            product=self.env['product.product'].browse(product).with_prefetch(all_product_ids)
            warehouse=self.env['stock.warehouse'].browse(warehouse).with_prefetch(all_warehouse_ids)
            rules=product._get_rules_from_location(warehouse.lot_stock_id)
            lead_days=rules.with_context(bypass_delay_description=True)._get_lead_days(product)[0]
            pwh_per_day[(lead_days,warehouse)].append(product.id)
        for(days,warehouse),p_idsinpwh_per_day.items():
            products=self.env['product.product'].browse(p_ids)
            qties=products.with_context(
                warehouse=warehouse.id,
                to_date=fields.datetime.now()+relativedelta.relativedelta(days=days)
            ).read(['virtual_available'])
            for(product,qty)inzip(products,qties):
                iffloat_compare(qty['virtual_available'],0,precision_rounding=product.uom_id.rounding)>=0:
                    key_to_remove.append((qty['id'],warehouse.id))
                else:
                    to_refill[(qty['id'],warehouse.id)]=qty['virtual_available']

        forkeyinkey_to_remove:
            delto_refill[key]
        ifnotto_refill:
            returnaction

        #Removeincomingquantityfromotheroriginthanmoves(e.gRFQ)
        product_ids,warehouse_ids=zip(*to_refill)
        dummy,qty_by_product_wh=self.env['product.product'].browse(product_ids)._get_quantity_in_progress(warehouse_ids=warehouse_ids)
        rounding=self.env['decimal.precision'].precision_get('ProductUnitofMeasure')
        #Grouporderpointbyproduct-warehouse
        orderpoint_by_product_warehouse=self.env['stock.warehouse.orderpoint'].read_group(
            [('id','in',orderpoints.ids)],
            ['product_id','warehouse_id','qty_to_order:sum'],
            ['product_id','warehouse_id'],lazy=False)
        orderpoint_by_product_warehouse={
            (record.get('product_id')[0],record.get('warehouse_id')[0]):record.get('qty_to_order')
            forrecordinorderpoint_by_product_warehouse
        }
        for(product,warehouse),product_qtyinto_refill.items():
            qty_in_progress=qty_by_product_wh.get((product,warehouse))or0.0
            qty_in_progress+=orderpoint_by_product_warehouse.get((product,warehouse),0.0)
            #Addqtytoorderforotherorderpointunderthiswarehouse.
            ifnotqty_in_progress:
                continue
            to_refill[(product,warehouse)]=product_qty+qty_in_progress
        to_refill={k:vfork,vinto_refill.items()iffloat_compare(
            v,0.0,precision_digits=rounding)<0.0}

        lot_stock_id_by_warehouse=self.env['stock.warehouse'].with_context(active_test=False).search_read([
            ('id','in',[g[1]forginto_refill.keys()])
        ],['lot_stock_id'])
        lot_stock_id_by_warehouse={w['id']:w['lot_stock_id'][0]forwinlot_stock_id_by_warehouse}

        #Witharchivedonestoavoid`product_location_check`SQLconstraints
        orderpoint_by_product_location=self.env['stock.warehouse.orderpoint'].with_context(active_test=False).read_group(
            [('id','in',orderpoints.ids)],
            ['product_id','location_id','ids:array_agg(id)'],
            ['product_id','location_id'],lazy=False)
        orderpoint_by_product_location={
            (record.get('product_id')[0],record.get('location_id')[0]):record.get('ids')[0]
            forrecordinorderpoint_by_product_location
        }

        orderpoint_values_list=[]
        for(product,warehouse),product_qtyinto_refill.items():
            lot_stock_id=lot_stock_id_by_warehouse[warehouse]
            orderpoint_id=orderpoint_by_product_location.get((product,lot_stock_id))
            iforderpoint_id:
                self.env['stock.warehouse.orderpoint'].browse(orderpoint_id).qty_forecast+=product_qty
            else:
                orderpoint_values=self.env['stock.warehouse.orderpoint']._get_orderpoint_values(product,lot_stock_id)
                orderpoint_values.update({
                    'name':_('ReplenishmentReport'),
                    'warehouse_id':warehouse,
                    'company_id':self.env['stock.warehouse'].browse(warehouse).company_id.id,
                })
                orderpoint_values_list.append(orderpoint_values)

        orderpoints=self.env['stock.warehouse.orderpoint'].with_user(SUPERUSER_ID).create(orderpoint_values_list)
        fororderpointinorderpoints:
            orderpoint_wh=orderpoint.location_id.get_warehouse()
            orderpoint.route_id=next((rforrinorderpoint.product_id.route_idsifnotr.supplied_wh_idorr.supplied_wh_id==orderpoint_wh),orderpoint.route_id)
            ifnotorderpoint.route_id:
                orderpoint._set_default_route_id()
        returnaction

    @api.model
    def_get_orderpoint_values(self,product,location):
        return{
            'product_id':product,
            'location_id':location,
            'product_max_qty':0.0,
            'product_min_qty':0.0,
            'trigger':'manual',
        }

    def_get_replenishment_order_notification(self):
        self.ensure_one()
        domain=[('orderpoint_id','in',self.ids)]
        ifself.env.context.get('written_after'):
            domain=expression.AND([domain,[('write_date','>',self.env.context.get('written_after'))]])
        move=self.env['stock.move'].search(domain,limit=1)
        ifmove.picking_id:
            return{
                'type':'ir.actions.client',
                'tag':'display_notification',
                'params':{
                    'title':_('Theinter-warehousetransfershavebeengenerated'),
                    'sticky':False,
                }
            }
        returnFalse

    def_quantity_in_progress(self):
        """ReturnQuantitiesthatarenotyetinvirtualstockbutshouldbededucedfromorderpointrule
        (example:purchasescreatedfromorderpoints)"""
        returndict(self.mapped(lambdax:(x.id,0.0)))

    def_prepare_procurement_values(self,date=False,group=False):
        """Preparespecifickeyformovesorothercomponentsthatwillbecreatedfromastockrule
        commingfromanorderpoint.Thismethodcouldbeoverrideinordertoaddothercustomkeythatcould
        beusedinmove/pocreation.
        """
        date_planned=dateorfields.Date.today()
        return{
            'route_ids':self.route_id,
            'date_planned':date_planned,
            'date_deadline':dateorFalse,
            'warehouse_id':self.warehouse_id,
            'orderpoint_id':self,
            'group_id':grouporself.group_id,
        }

    def_procure_orderpoint_confirm(self,use_new_cursor=False,company_id=None,raise_user_error=True):
        """Createprocurementsbasedonorderpoints.
        :parambooluse_new_cursor:ifset,useadedicatedcursorandauto-commitafterprocessing
            1000orderpoints.
            Thisisappropriateforbatchjobsonly.
        """
        self=self.with_company(company_id)
        orderpoints_noprefetch=self.read(['id'])
        orderpoints_noprefetch=[orderpoint['id']fororderpointinorderpoints_noprefetch]
        fororderpoints_batchinsplit_every(1000,orderpoints_noprefetch):
            ifuse_new_cursor:
                cr=registry(self._cr.dbname).cursor()
                self=self.with_env(self.env(cr=cr))
            try:
                orderpoints_batch=self.env['stock.warehouse.orderpoint'].browse(orderpoints_batch)
                orderpoints_exceptions=[]
                whileorderpoints_batch:
                    procurements=[]
                    fororderpointinorderpoints_batch:
                        origins=orderpoint.env.context.get('origins',{}).get(orderpoint.id,False)
                        iforigins:
                            origin='%s-%s'%(orderpoint.display_name,','.join(origins))
                        else:
                            origin=orderpoint.name
                        iffloat_compare(orderpoint.qty_to_order,0.0,precision_rounding=orderpoint.product_uom.rounding)==1:
                            date=datetime.combine(orderpoint.lead_days_date,time.min)
                            values=orderpoint._prepare_procurement_values(date=date)
                            procurements.append(self.env['procurement.group'].Procurement(
                                orderpoint.product_id,orderpoint.qty_to_order,orderpoint.product_uom,
                                orderpoint.location_id,orderpoint.name,origin,
                                orderpoint.company_id,values))

                    try:
                        withself.env.cr.savepoint():
                            self.env['procurement.group'].with_context(from_orderpoint=True).run(procurements,raise_user_error=raise_user_error)
                    exceptProcurementExceptionaserrors:
                        forprocurement,error_msginerrors.procurement_exceptions:
                            orderpoints_exceptions+=[(procurement.values.get('orderpoint_id'),error_msg)]
                        failed_orderpoints=self.env['stock.warehouse.orderpoint'].concat(*[o[0]foroinorderpoints_exceptions])
                        ifnotfailed_orderpoints:
                            _logger.error('Unabletoprocessorderpoints')
                            break
                        orderpoints_batch-=failed_orderpoints

                    exceptOperationalError:
                        ifuse_new_cursor:
                            cr.rollback()
                            continue
                        else:
                            raise
                    else:
                        orderpoints_batch._post_process_scheduler()
                        break

                #Loganactivityonproducttemplateforfailedorderpoints.
                fororderpoint,error_msginorderpoints_exceptions:
                    existing_activity=self.env['mail.activity'].search([
                        ('res_id','=',orderpoint.product_id.product_tmpl_id.id),
                        ('res_model_id','=',self.env.ref('product.model_product_template').id),
                        ('note','=',error_msg)])
                    ifnotexisting_activity:
                        orderpoint.product_id.product_tmpl_id.activity_schedule(
                            'mail.mail_activity_data_warning',
                            note=error_msg,
                            user_id=orderpoint.product_id.responsible_id.idorSUPERUSER_ID,
                        )
            finally:
                ifuse_new_cursor:
                    try:
                        cr.commit()
                    finally:
                        cr.close()

        return{}

    def_post_process_scheduler(self):
        returnTrue
